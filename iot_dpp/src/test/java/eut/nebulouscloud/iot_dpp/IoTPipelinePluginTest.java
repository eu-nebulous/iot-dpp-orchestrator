package eut.nebulouscloud.iot_dpp;

import static org.junit.jupiter.api.Assertions.assertEquals;
import static org.junit.jupiter.api.Assertions.assertFalse;
import static org.junit.jupiter.api.Assertions.assertTrue;

import java.nio.file.Files;
import java.nio.file.Path;
import java.util.Collections;
import java.util.Date;
import java.util.HashMap;
import java.util.LinkedList;
import java.util.List;
import java.util.Map;
import java.util.Optional;
import java.util.Random;
import java.util.Set;

import org.apache.activemq.artemis.api.core.Pair;
import org.apache.activemq.artemis.core.config.ClusterConnectionConfiguration;
import org.apache.activemq.artemis.core.config.Configuration;
import org.apache.activemq.artemis.core.config.DivertConfiguration;
import org.apache.activemq.artemis.core.config.TransformerConfiguration;
import org.apache.activemq.artemis.core.config.impl.ConfigurationImpl;
import org.apache.activemq.artemis.core.security.CheckType;
import org.apache.activemq.artemis.core.security.Role;
import org.apache.activemq.artemis.core.server.ActiveMQServer;
import org.apache.activemq.artemis.core.server.cluster.impl.MessageLoadBalancingType;
import org.apache.activemq.artemis.core.server.embedded.EmbeddedActiveMQ;
import org.apache.activemq.artemis.core.server.impl.ActiveMQServerImpl;
import org.apache.activemq.artemis.spi.core.security.ActiveMQSecurityManager;
import org.eclipse.paho.client.mqttv3.IMqttClient;
import org.eclipse.paho.client.mqttv3.IMqttDeliveryToken;
import org.eclipse.paho.client.mqttv3.MqttCallback;
import org.eclipse.paho.client.mqttv3.MqttClient;
import org.eclipse.paho.client.mqttv3.MqttConnectOptions;
import org.eclipse.paho.client.mqttv3.MqttException;
import org.eclipse.paho.client.mqttv3.MqttMessage;
import org.eclipse.paho.client.mqttv3.MqttPersistenceException;
import org.junit.jupiter.api.Test;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import com.fasterxml.jackson.core.JsonProcessingException;
import com.fasterxml.jackson.databind.ObjectMapper;

import eut.nebulouscloud.iot_dpp.GroupIDExtractionParameters.GroupIDExpressionSource;
import eut.nebulouscloud.iot_dpp.monitoring.QueuesMonitoringMessage;
import eut.nebulouscloud.iot_dpp.monitoring.QueuesMonitoringPlugin;
import eut.nebulouscloud.iot_dpp.monitoring.QueuesMonitoringPlugin.QueuesMonitoringPluginConsumer;
import eut.nebulouscloud.iot_dpp.monitoring.events.MessageLifecycleEvent;
import eut.nebulouscloud.iot_dpp.pipeline.IoTPipelineConfigurator;
import eut.nebulouscloud.iot_dpp.pipeline.IoTPipelineStepConfiguration;
import java.util.concurrent.CompletableFuture;
import java.util.concurrent.Executors;
import java.util.concurrent.ScheduledExecutorService;
import java.util.concurrent.TimeUnit;
/**
 * Test the correct functionaltiy of QueuesMonitoringPlugin
 */
class IoTPipelinePluginTest {
	ObjectMapper om = new ObjectMapper();
	static Logger LOGGER = LoggerFactory.getLogger(IoTPipelinePluginTest.class);
	static int QueuesMonitoringProcesQueryIntervalSeconds = 3;

	/**
	 * Creates a local ActiveMQ server listening at localhost:61616. The server
	 * accepts requests from any user. Configures the MessageMonitoringPluging and
	 * sets it to store generated events in the provided events list
	 * 
	 * @param events A list that will contain all the events generated by the
	 *               MessageMonitoringPluging
	 * @return the created MessageMonitoringPluging instance.
	 * @throws Exception
	 */
	private EmbeddedActiveMQ createActiveMQBroker(String nodeName, int port,
			Map<String, IoTPipelineStepConfiguration> pipelineSteps, List<Integer> otherServers,List<List<QueuesMonitoringMessage>> queuesMonitoringMessage) throws Exception {
		Configuration config = new ConfigurationImpl();
		config.setName(nodeName);
		String foldersRoot = "data/" + new Date().getTime() + "/data_" + port;
		config.setBindingsDirectory(foldersRoot + "/bindings");
		config.setJournalDirectory(foldersRoot + "/journal");
		config.setJournalRetentionDirectory(foldersRoot + "/journalRetention");
		config.setLargeMessagesDirectory(foldersRoot + "/lm");
		config.setNodeManagerLockDirectory(foldersRoot + "/nodeManagerLock");
		config.setPagingDirectory(foldersRoot + "/paging");
		config.addConnectorConfiguration("serverAt" + port + "Connector", "tcp://localhost:" + port);
		config.addAcceptorConfiguration("netty", "tcp://localhost:" + port);
		config.addAcceptorConfiguration("vm", "vm://0");
		

		ClusterConnectionConfiguration cluster = new ClusterConnectionConfiguration();
		cluster.setAddress("");
		cluster.setConnectorName("serverAt" + port + "Connector");
		cluster.setName("my-cluster");
		cluster.setAllowDirectConnectionsOnly(false);
		cluster.setMessageLoadBalancingType(MessageLoadBalancingType.ON_DEMAND);
		cluster.setRetryInterval(100);
		config.setClusterConfigurations(List.of(cluster));
		if (otherServers != null) {
			for (Integer otherPort : otherServers) {
				cluster.setStaticConnectors(List.of("serverAt" + otherPort + "Connector"));
				config.addConnectorConfiguration("serverAt" + otherPort + "Connector", "tcp://localhost:" + otherPort);
			}
		}

		IoTPipelineConfigurator configuratorPlugin = new IoTPipelineConfigurator();
		configuratorPlugin.init(
				Map.of(IoTPipelineConfigurator.IOT_DPP_PIPELINE_STEPS_ENV_VAR, om.writeValueAsString(pipelineSteps)));//falta port
		config.getBrokerPlugins().add(configuratorPlugin);
		
		QueuesMonitoringPlugin plugin = new QueuesMonitoringPlugin();
		plugin.init(Map.of("monitored_queue_regex","^all\\.iotdpp\\..*","local_activemq_url","tcp://localhost:"+port,"query_interval_seconds",""+QueuesMonitoringProcesQueryIntervalSeconds));
		plugin.registered(null);
		plugin.process.consumer = new QueuesMonitoringPluginConsumer() {

			@Override
			public void consume(List<QueuesMonitoringMessage> messages) {
				queuesMonitoringMessage.add(messages);

			}
		};
		config.getBrokerMessagePlugins().add(plugin);
		
		EmbeddedActiveMQ server = new EmbeddedActiveMQ();
		server.setSecurityManager(new ActiveMQSecurityManager() {
			@Override
			public boolean validateUserAndRole(String user, String password, Set<Role> roles, CheckType checkType) {
				return true;
			}

			@Override
			public boolean validateUser(String user, String password) {
				return true;
			}
		});
		server.setConfiguration(config);
		server.start();
		while (!server.getActiveMQServer().isActive()) {
		    System.out.println("Waiting for server to start...");
		    Thread.sleep(500);
		}
		return server;
	}

	private EmbeddedActiveMQ createActiveMQBroker(String nodeName,
			Map<String, IoTPipelineStepConfiguration> pipelineSteps,int port, List<List<QueuesMonitoringMessage>> result) throws Exception {
		return createActiveMQBroker(nodeName, port, pipelineSteps, null,result);
	}

	private IMqttClient buildWorker(String brokerURL, String clientId, String inputTopic, String outputTopic,
			List<MessageReceptionRecord> messages) throws Exception {
		IMqttClient consumer = new MqttClient("tcp://" + brokerURL, clientId);
		
		ScheduledExecutorService scheduler = Executors.newScheduledThreadPool(1);
		List<Pair<String, byte[]>> outputMessagesList = Collections
				.synchronizedList(new LinkedList<Pair<String, byte[]>>());
		
		consumer.setCallback(new MqttCallback() {

			@Override
			public void messageArrived(String topic, MqttMessage message) throws Exception {
				messages.add(new MessageReceptionRecord(consumer.getClientId(), topic,
						om.readValue(new String(message.getPayload()), TestMessage.class)));
				LOGGER.info("Worker "+consumer.getClientId()+" messageArrived "+message.getId());
				outputMessagesList.add(new Pair(outputTopic.replaceAll("\\.", "\\/"), message.getPayload()));
			}

			@Override
			public void deliveryComplete(IMqttDeliveryToken token) {
				//LOGGER.info("Worker "+consumer.getClientId()+" deliveryComplete "+token);
			}

			@Override
			public void connectionLost(Throwable cause) {
				LOGGER.error("Worker "+consumer.getClientId() + " connectionLost", cause);
			}
		});
		MqttConnectOptions opts = new MqttConnectOptions();
		// opts.setUserName("artemis");
		// opts.setPassword("artemis".toCharArray());
		opts.setCleanSession(false);
		consumer.connect(opts);
		String subs = inputTopic.replaceAll("\\.", "\\/");
		LOGGER.info("Subscribing to "+subs);
		consumer.subscribe(subs, 2);
		

	        
	      new Thread( new  Runnable() {
			
			@Override
			public void run() {
				while(true)
				{
		    	  while(!outputMessagesList.isEmpty())
					 {
						 Pair<String,byte[]> m = outputMessagesList.remove(0);
						 try {
							consumer.publish(m.getA(), m.getB(), 2, false);
						} catch (MqttPersistenceException e) {
							// TODO Auto-generated catch block
							e.printStackTrace();
						} catch (MqttException e) {
							// TODO Auto-generated catch block
							e.printStackTrace();
						}
						 try {
							Thread.sleep(100);
						} catch (InterruptedException e) {
							// TODO Auto-generated catch block
							e.printStackTrace();
						}
					 }
		    	  try {
						Thread.sleep(100);
					} catch (InterruptedException e) {
						// TODO Auto-generated catch block
						e.printStackTrace();
					}
				}
			}
		}).start();

		
		
		
		
		return consumer;
	}
	
	
	
	private Optional<QueuesMonitoringMessage> getLastMessageFromTopic(List<List<QueuesMonitoringMessage>> queuesMonitoringMessages, String topic)
	{
		return queuesMonitoringMessages.get(queuesMonitoringMessages.size()-1).stream().filter(m->m.queue.equals(topic)).findFirst();
	}
	
	//@Test
	void otherTest() throws JsonProcessingException
	{
		/*Map<String, IoTPipelineStepConfiguration> map = new HashMap<String, IoTPipelineStepConfiguration>();
		map.put("stepA", new IoTPipelineStepConfiguration("src",
				new GroupIDExtractionParameters(GroupIDExpressionSource.BODY_JSON, "fieldA")));
		map.put("stepB", new IoTPipelineStepConfiguration("stepA",
				new GroupIDExtractionParameters(GroupIDExpressionSource.BODY_JSON, "fieldB")));
		
		IoTPipelineConfigurator configuratorPlugin = new IoTPipelineConfigurator();
		configuratorPlugin.init(
				Map.of(IoTPipelineConfigurator.IOT_DPP_PIPELINE_STEPS_ENV_VAR, om.writeValueAsString(map),
						"local_activemq_url", "tcp://localhost:6161",
						"local_activemq_user","artemis","local_activemq_password","artemis"));
				configuratorPlugin.registered(null);
			*/		
		
		
		
		
		QueuesMonitoringPlugin plugin = new QueuesMonitoringPlugin();
		plugin.init(Map.of(
				"monitored_queue_regex","^all\\.iotdpp\\.*","query_interval_seconds",""+QueuesMonitoringProcesQueryIntervalSeconds));
		plugin.registered(null);
		plugin.process.consumer = new QueuesMonitoringPluginConsumer() {

			@Override
			public void consume(List<QueuesMonitoringMessage> messages) {
				LOGGER.info(messages.toString());
				//result.add(messages);

			}
		};
		
		//config.getBrokerMessagePlugins().add(plugin);
		
		

		
		while(true)
		{
			try {
				Thread.sleep(1000);
			} catch (InterruptedException e) {
				// TODO Auto-generated catch block
				e.printStackTrace();
			}
		}
	}

	/**
	 * Test message monitoring plugin when MQTT clients are interacting with the
	 * ActiveMQ broker.
	 * 
	 * @throws Exception
	 */
	@Test
	void MQTTTestSingleNode() throws Exception {

		/**
		 * Create a local ActiveMQ server
		 */
		// String testTopic = ;
		int brokerPort = 6169;
		String brokerURL = "localhost:" + brokerPort;
		// localhost:1883"
		Map<String, IoTPipelineStepConfiguration> map = new HashMap<String, IoTPipelineStepConfiguration>();
		map.put("stepA", new IoTPipelineStepConfiguration("src",
				new GroupIDExtractionParameters(GroupIDExpressionSource.BODY_JSON, "fieldA")));
		map.put("stepB", new IoTPipelineStepConfiguration("stepA",
				new GroupIDExtractionParameters(GroupIDExpressionSource.BODY_JSON, "fieldB")));
		EmbeddedActiveMQ broker = null;
		try {
			List<List<QueuesMonitoringMessage>> queuesMonitoringMessages = new LinkedList<List<QueuesMonitoringMessage>>();
			broker = createActiveMQBroker("test-server", map, brokerPort,queuesMonitoringMessages);
			List<MessageReceptionRecord> messages = Collections
					.synchronizedList(new LinkedList<MessageReceptionRecord>());
			
			Thread.sleep(5*1000);
			/**
			 * Publish a message to the topic
			 */
			LOGGER.info("Send messages to "+IoTPipelineConfigurator.IOT_DPP_TOPICS_PREFIX+"src.output");
			IMqttClient publisher = new MqttClient("tcp://" + brokerURL, "publisher");
			MqttConnectOptions connOpts = new MqttConnectOptions();
			connOpts.setUserName("artemis");
			connOpts.setPassword("artemis".toCharArray());

			publisher.connect(connOpts);
			
			
			/**
			 * Send some messages to src topic
			 */
			int messagesCount = 60;
			Random rand = new Random();
			for (int i = 0; i < messagesCount; i++) {
				TestMessage payload = new TestMessage(i, rand.nextInt(1, 10), rand.nextInt(1, 10));
				MqttMessage message = new MqttMessage(om.writeValueAsString(payload).getBytes());
				LOGGER.info("publish "+message.getId());
				message.setQos(2);
				publisher.publish("iotdpp/src/output", message);
				Thread.sleep(1);
			}
			
			/**
			 * Assert that the list of pending messages in step A is == messagesCount as the worker is stopped.
			 * Assert that the list of pending messages in step B is == 0 as messages werent processed on previous step.
			 */
			LOGGER.info("Wait for metrics to be collected");
			Thread.sleep(QueuesMonitoringProcesQueryIntervalSeconds*1000*3);			
			assertFalse(queuesMonitoringMessages.isEmpty());
			Optional<QueuesMonitoringMessage> monitoringMessageStepA = getLastMessageFromTopic(queuesMonitoringMessages, "all."+IoTPipelineConfigurator.IOT_DPP_TOPICS_PREFIX+"stepA.input.src");
			assertTrue(monitoringMessageStepA.isPresent());
			assertEquals(messagesCount,monitoringMessageStepA.get().messageCount);
			
			Optional<QueuesMonitoringMessage> monitoringMessageStepB = getLastMessageFromTopic(queuesMonitoringMessages, "all."+IoTPipelineConfigurator.IOT_DPP_TOPICS_PREFIX+"stepB.input.stepA");
			assertTrue(monitoringMessageStepB.isPresent());
			assertEquals(0,monitoringMessageStepB.get().messageCount);
			
			/**
			 * Start woker A. Allow some time to process messages
			 */
			LOGGER.info("Start woker A");
			IMqttClient stepAWorker1 = buildWorker(brokerURL, "step_A_worker_1", "$share/all/"+IoTPipelineConfigurator.IOT_DPP_TOPICS_PREFIX+"stepA.input.src",IoTPipelineConfigurator.IOT_DPP_TOPICS_PREFIX+"stepA.output",
					messages);
			IMqttClient stepAWorker2 = buildWorker(brokerURL, "step_A_worker_2", "$share/all/"+IoTPipelineConfigurator.IOT_DPP_TOPICS_PREFIX+"stepA.input.src",IoTPipelineConfigurator.IOT_DPP_TOPICS_PREFIX+"stepA.output",
					messages);
			LOGGER.info("Wait for metrics to be collected");
			Thread.sleep(QueuesMonitoringProcesQueryIntervalSeconds*1000*3);
			
			/**
			 * Assert that the list of pending messages in step A is == 0 as thy were all processed.
			 * Assert that the list of pending messages in step B is == messagesCount as step B is not working.
			 */
			monitoringMessageStepA = getLastMessageFromTopic(queuesMonitoringMessages, "all."+IoTPipelineConfigurator.IOT_DPP_TOPICS_PREFIX+"stepA.input.src");
			assertTrue(monitoringMessageStepA.isPresent());
			assertEquals(0,monitoringMessageStepA.get().messageCount);
			
			monitoringMessageStepB = getLastMessageFromTopic(queuesMonitoringMessages, "all."+IoTPipelineConfigurator.IOT_DPP_TOPICS_PREFIX+"stepB.input.stepA");
			assertTrue(monitoringMessageStepB.isPresent());
			assertEquals(messagesCount,monitoringMessageStepB.get().messageCount);
			
			/**
			 * Start woker B. Allow some time to process messages
			 */
			LOGGER.info("Start woker B");
			IMqttClient stepBWorker1 = buildWorker(brokerURL, "step_B_worker_1","$share/all/"+IoTPipelineConfigurator.IOT_DPP_TOPICS_PREFIX+"stepB.input.stepA",IoTPipelineConfigurator.IOT_DPP_TOPICS_PREFIX+"stepB.output",
					messages);
			IMqttClient stepBWorker2 = buildWorker(brokerURL, "step_B_worker_2", "$share/all/"+IoTPipelineConfigurator.IOT_DPP_TOPICS_PREFIX+"stepB.input.stepA",IoTPipelineConfigurator.IOT_DPP_TOPICS_PREFIX+"stepB.output",
					messages);
			LOGGER.info("Wait for metrics to be collected");
			Thread.sleep(QueuesMonitoringProcesQueryIntervalSeconds*1000*3);
			
			/**
			 * Assert that the list of pending messages in step B is == 0 as thy were all processed.
			 */
			
			monitoringMessageStepB = getLastMessageFromTopic(queuesMonitoringMessages, "all."+IoTPipelineConfigurator.IOT_DPP_TOPICS_PREFIX+"stepB.input.stepA");
			assertTrue(monitoringMessageStepB.isPresent());
			assertEquals(0,monitoringMessageStepB.get().messageCount);
			
			/**
			 * Assert that, for each step A and B, messages for different groupings are processed by different workers.
			 */
			for (String step : List.of("A", "B")) {
				List<MessageReceptionRecord> stepInputMessages = messages.stream()
						.filter(m -> m.consumerId.startsWith("step_" + step)).toList();
				assertEquals(messagesCount, stepInputMessages.size());

				List<Integer> fieldWithGroupingKeyValues = stepInputMessages.stream().map(m -> m.payload.getField(step))
						.distinct().toList();
				for (Integer groupingKeyValue : fieldWithGroupingKeyValues) {
					LOGGER.info("For step "+step+" messages for groping key "+groupingKeyValue+" where processed by steps: "+stepInputMessages.stream().filter(m -> m.payload.getField(step) == groupingKeyValue)
							.map(m -> m.consumerId).distinct().toList());
					assertEquals(1, stepInputMessages.stream().filter(m -> m.payload.getField(step) == groupingKeyValue)
							.map(m -> m.consumerId).distinct().count());
				}

			}

		} finally {
			try {
				broker.stop();
			} catch (Exception e) {
			}
		}

	}

}
